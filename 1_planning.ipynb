{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.29-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
      "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
      "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.31-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3,>=1 (from langchain)\n",
      "  Using cached pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting anyio<5,>=3 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.9.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic<3,>=1->langchain)\n",
      "  Using cached pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "Using cached pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.29-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "Using cached greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (620 kB)\n",
      "Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "Using cached orjson-3.9.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: urllib3, tenacity, sniffio, PyYAML, pydantic-core, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, idna, greenlet, frozenlist, charset-normalizer, certifi, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, pydantic, marshmallow, jsonpatch, anyio, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.29 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.3.0 attrs-23.2.0 certifi-2024.2.2 charset-normalizer-3.3.2 dataclasses-json-0.6.4 frozenlist-1.4.1 greenlet-3.0.3 idna-3.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.9.15 packaging-23.2 pydantic-2.6.4 pydantic-core-2.16.3 requests-2.31.0 sniffio-1.3.1 tenacity-8.2.3 typing-inspect-0.9.0 urllib3-2.2.1 yarl-1.9.4\n",
      "Requirement already satisfied: langchain-community in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (0.0.29)\n",
      "Collecting tavily-python\n",
      "  Downloading tavily_python-0.3.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-community) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-community) (0.1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-community) (0.1.31)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-community) (8.2.3)\n",
      "Collecting tiktoken==0.5.2 (from tavily-python)\n",
      "  Using cached tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken==0.5.2->tavily-python)\n",
      "  Using cached regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (4.3.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (2.6.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.9.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.10.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-community) (2.16.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading tavily_python-0.3.1-py3-none-any.whl (5.4 kB)\n",
      "Using cached tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "Installing collected packages: regex, tiktoken, tavily-python\n",
      "Successfully installed regex-2023.12.25 tavily-python-0.3.1 tiktoken-0.5.2\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.5\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: numpy in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\n",
      "Downloading faiss_cpu-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.15-py3-none-any.whl.metadata (621 bytes)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from langchainhub) (2.31.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.31.0.20240311-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
      "Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Downloading types_requests-2.31.0.20240311-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.15 types-requests-2.31.0.20240311\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.16.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from wandb) (5.9.8)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.43.0-py2.py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from wandb) (68.2.2)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading sentry_sdk-1.43.0-py2.py3-none-any.whl (264 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, Click, gitdb, GitPython, wandb\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.42 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 protobuf-4.25.3 sentry-sdk-1.43.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.4\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain\n",
    "! pip install -U langchain-community tavily-python\n",
    "! pip install --upgrade --quiet langchain-openai tavily-python\n",
    "! pip install beautifulsoup4\n",
    "! pip install faiss-cpu\n",
    "! pip install langchainhub\n",
    "! pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "config = yaml.safe_load(open(\"myconfig.yml\"))\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"OPENAI_API_KEY\"]\n",
    "os.environ[\"TAVILY_API_KEY\"] = config[\"TAVILY_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = config[\"LANGCHAIN_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = config[\"LANGCHAIN_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = str(config[\"LANGCHAIN_TRACING_V2\"]).lower()\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = config[\"LANGCHAIN_ENDPOINT\"]\n",
    "os.environ[\"LANGCHAIN_HUB_API_URL\"] = config[\"LANGCHAIN_HUB_API_URL\"]\n",
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = str(config[\"LANGCHAIN_WANDB_TRACING\"]).lower()\n",
    "os.environ[\"WANDB_PROJECT\"] = config[\"WANDB_PROJECT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning\n",
    "\n",
    "![images/Screenshot 2024-02-21 at 16.17.22.png](<images/Screenshot 2024-02-21 at 16.17.22.png>)\n",
    "\n",
    "You might have come across various techniques aimed at improving the performance of large language models, such as offering tips or even jokingly threatening them. One popular technique is called \"chain of thought,\" where the model is asked to think step by step, enabling self-correction. This approach has evolved into more advanced versions like \"chain of thought with self-consistency\" and the generalized \"tree of thoughts,\" where multiple thoughts are created, re-evaluated, and consolidated to provide an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree of Thoughts\n",
    "\n",
    "The [@astropomeai tutorial](https://medium.com/@astropomeai/implementing-the-tree-of-thoughts-in-langchains-chain-f2ebc5864fac) on Tree of Thoughts is used as basis of this exercise but expanded with LLMOps tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "cot_step1 = hub.pull(\"rachnogstyle/nlw_jan24_cot_step1\")\n",
    "cot_step2 = hub.pull(\"rachnogstyle/nlw_jan24_cot_step2\")\n",
    "cot_step3 = hub.pull(\"rachnogstyle/nlw_jan24_cot_step3\")\n",
    "cot_step4 = hub.pull(\"rachnogstyle/nlw_jan24_cot_step4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p72admin/miniconda3/envs/autogpt/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "chain1 = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0, model=model),\n",
    "    prompt=cot_step1,\n",
    "    output_key=\"solutions\"\n",
    ")\n",
    "\n",
    "chain2 = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0, model=model),\n",
    "    prompt=cot_step2,\n",
    "    output_key=\"review\"\n",
    ")\n",
    "\n",
    "chain3 = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0, model=model),\n",
    "    prompt=cot_step3,\n",
    "    output_key=\"deepen_thought_process\"\n",
    ")\n",
    "\n",
    "chain4 = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0, model=model),\n",
    "    prompt=cot_step4,\n",
    "    output_key=\"ranked_solutions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'human colonization of Mars', 'perfect_factors': 'The distance between Earth and Mars is very large, making regular resupply difficult', 'ranked_solutions': \"Developing sustainable habitats on Mars (Rank: 1)\\n\\nJustification: This solution has the highest potential for long-term success in establishing a sustainable human presence on Mars. By focusing on creating habitats that can support life in a harsh environment, this solution addresses the core challenge of colonization. The partnerships and strategies outlined provide a solid foundation for implementation, and the potential obstacles and unexpected outcomes are manageable with proper planning and flexibility.\\n\\nFinal thoughts: While this solution may require significant resources and effort, the potential benefits of establishing sustainable habitats on Mars are immense. By prioritizing this solution, we can work towards a future where humans can thrive on another planet.\\n\\nB: Terraforming Mars (Rank: 2)\\n\\nJustification: Terraforming Mars has the potential to create a more Earth-like environment, but the challenges and uncertainties involved make it a less promising solution compared to developing sustainable habitats. The timeline for terraforming is long-term and the risks of unintended consequences are high. Additionally, the ethical considerations of altering an entire planet's ecosystem are significant.\\n\\nFinal thoughts: While terraforming Mars may be a fascinating concept, the practicality and feasibility of this solution are questionable. It may be more prudent to focus on more achievable goals, such as creating sustainable habitats, before considering more drastic measures like terraforming.\\n\\nC: Sending humans to Mars for short-term missions (Rank: 3)\\n\\nJustification: While sending humans to Mars for short-term missions may be a more immediate goal, it does not address the long-term challenge of establishing a sustainable human presence on the planet. Without sustainable habitats or infrastructure in place, short-term missions may not be sustainable or beneficial in the long run.\\n\\nFinal thoughts: Short-term missions to Mars may be valuable for scientific research and exploration, but they should be seen as stepping stones towards the larger goal of colonization. It is important to prioritize solutions that address the fundamental challenges of living on Mars in the long term.\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain1, chain2, chain3, chain4],\n",
    "    input_variables=[\"input\", \"perfect_factors\"],\n",
    "    output_variables=[\"ranked_solutions\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\n",
    "        overall_chain(\n",
    "            {\n",
    "                \"input\": \"human colonization of Mars\",\n",
    "                \"perfect_factors\": \"The distance between Earth and Mars is very large, making regular resupply difficult\"\n",
    "            }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct prompt overview\n",
    "\n",
    "Let's review [ReAct](https://python.langchain.com/docs/modules/agents/agent_types/react) prompt as it's defined in Langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "prompt.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-ask with search\n",
    "\n",
    "Let's review [self-ask with search](https://python.langchain.com/docs/modules/agents/agent_types/self_ask_with_search) as it's defined in Langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question: Who lived longer, Muhammad Ali or Alan Turing?\\nAre follow up questions needed here: Yes.\\nFollow up: How old was Muhammad Ali when he died?\\nIntermediate answer: Muhammad Ali was 74 years old when he died.\\nFollow up: How old was Alan Turing when he died?\\nIntermediate answer: Alan Turing was 41 years old when he died.\\nSo the final answer is: Muhammad Ali\\n\\nQuestion: When was the founder of craigslist born?\\nAre follow up questions needed here: Yes.\\nFollow up: Who was the founder of craigslist?\\nIntermediate answer: Craigslist was founded by Craig Newmark.\\nFollow up: When was Craig Newmark born?\\nIntermediate answer: Craig Newmark was born on December 6, 1952.\\nSo the final answer is: December 6, 1952\\n\\nQuestion: Who was the maternal grandfather of George Washington?\\nAre follow up questions needed here: Yes.\\nFollow up: Who was the mother of George Washington?\\nIntermediate answer: The mother of George Washington was Mary Ball Washington.\\nFollow up: Who was the father of Mary Ball Washington?\\nIntermediate answer: The father of Mary Ball Washington was Joseph Ball.\\nSo the final answer is: Joseph Ball\\n\\nQuestion: Are both the directors of Jaws and Casino Royale from the same country?\\nAre follow up questions needed here: Yes.\\nFollow up: Who is the director of Jaws?\\nIntermediate answer: The director of Jaws is Steven Spielberg.\\nFollow up: Where is Steven Spielberg from?\\nIntermediate answer: The United States.\\nFollow up: Who is the director of Casino Royale?\\nIntermediate answer: The director of Casino Royale is Martin Campbell.\\nFollow up: Where is Martin Campbell from?\\nIntermediate answer: New Zealand.\\nSo the final answer is: No\\n\\nQuestion: {input}\\nAre followup questions needed here:{agent_scratchpad}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/self-ask-with-search\")\n",
    "prompt.template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approaches to read next:\n",
    "\n",
    "**Reflexion** ([Shinn & Labash 2023](https://arxiv.org/abs/2303.11366)) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills.\n",
    "\n",
    "**Chain of Hindsight** (CoH; [Liu et al. 2023](https://arxiv.org/abs/2302.02676)) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
